{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b05cf6f-8fe4-49b8-91b0-692fe5c3d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from llm.process import *\n",
    "from llm.data_utils import *\n",
    "from llm.eval_utils import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68bda216-371b-4c98-8cc3-5e7eebfb66d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/elicer/ABSA_KO/outputs/llm/acos_rest16_trans_5shot_result.txt'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # dataset parameters\n",
    "        self.path = '/home/elicer/ABSA_KO'\n",
    "        self.data_path = f'{self.path}/data'\n",
    "        self.model = 'llm'\n",
    "        self.version = 'gpt-4-1106-preview'\n",
    "        self.task = 'acos' # task \n",
    "        self.dataset = 'rest16' # data \n",
    "        self.prompt_type = \"trans_5shot\"\n",
    "        self.do_inference = True\n",
    "        self.eval_data_split = 'test' # test or dev\n",
    "        self.temperature = 0 \n",
    "        self.max_seq_length = 2000 \n",
    "        self.lowercase = True\n",
    "        self.single_view_type = 'rand'\n",
    "        self.seed = 25\n",
    "        self.sort_label = False\n",
    "        self.multi_task = False\n",
    "        self.ctrl_token = \"post\"\n",
    "\n",
    "args = Args()\n",
    "output_path = f'{args.path}/outputs/{args.model}/{args.task}_{args.dataset}_{args.prompt_type}_result.txt'\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eefea1ee-55a5-43d4-a5ce-7a387087f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "data_path = f'{args.data_path}/{args.task}/{args.dataset}/{args.eval_data_split}.txt'\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    inputs = [line.strip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "495d6d6f-4edc-4ed6-953d-307428d10d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inputs = list(inputs[367:368])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7fc34b20-de36-4134-a2f3-2685eadde2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우리 두 사람은 특히 야심차게, 쉴쇼 샘플러에 돈을 아낌없이 썼습니다... 거대한 흰색 걸프 새우, 훈제된 알바코어 참치, 딜로 양념된 레이의 환상적인 마닐라 조개, 맛있는 간장 드레싱에 버무린 가리비, 그리고 황홀한 버터 소스 위에 올려진 조그만 덩어리의 던지네스 크랩의 아름다운 조합이었습니다.####[['흰색 걸프 새우', '음식 옵션', '긍정적', '거대한'], ['마닐라 조개', '음식 품질', '긍정적', '환상적인'], ['간장 드레싱', '음식 품질', '긍정적', '맛있는'], ['버터 소스', '음식 품질', '긍정적', '황홀한']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# do inference\n",
    "if args.do_inference:\n",
    "    prompt_path = f'{args.path}/src/{args.model}'\n",
    "    \n",
    "    predicts = []\n",
    "    for index, input_item in enumerate(new_inputs):\n",
    "        try:\n",
    "            prompt = process_prompt(input_item, prompt_path, args.task, args.dataset, args.prompt_type)\n",
    "            target = llm_chat(prompt, args.version, args.temperature, args.max_seq_length)\n",
    "            print(target)\n",
    "            predicts.append(target)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing input at index {index}: {e}\")\n",
    "            if 'invalid syntax' in str(e):\n",
    "                print(target)\n",
    "                predicts.append(target)\n",
    "            else:\n",
    "                print(target)\n",
    "                predicts.append(None)\n",
    "        # save inference result\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be82cce-9a46-4c8e-b770-d2a15237b5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 171 elements to /home/elicer/ABSA_KO/data/acos/rest16/dev_ko.txt\n"
     ]
    }
   ],
   "source": [
    "save_path = f'{args.data_path}/{args.task}/{args.dataset}/{args.eval_data_split}_ko.txt'\n",
    "with open(save_path, 'w', encoding='utf-8') as file:\n",
    "    for line in predicts:\n",
    "        file.write(f\"{line}\\n\")\n",
    "print(\"Saved\",len(predicts),\"elements to\",save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978006f6-fbab-45cb-bceb-59ade0277a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp",
   "language": "python",
   "name": "mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
