{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c001de3-5966-450c-86f9-69e20ffd2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "def format_line(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\s*,\\s*', ' , ', line)\n",
    "    line = re.sub(r'\\s*\\.\\s*', ' . ', line)\n",
    "    line = re.sub(r\"n \\s*'\\s*t\", \"n't\", line)\n",
    "    return line\n",
    "\n",
    "def split_read(file_name):\n",
    "    inputs, targets =[], []\n",
    "    with open(file_name, 'r', encoding='UTF-8') as fp:\n",
    "        for line in fp:\n",
    "            input, target = [], []\n",
    "            input, target = line.strip().split('####')\n",
    "            if line != '':\n",
    "                inputs.append(input)\n",
    "                targets.append(target)\n",
    "    print('Data read. Total count: ',len(targets))\n",
    "    return inputs, targets\n",
    "\n",
    "def merge_save(inputs, targets, file_name, num=1):\n",
    "    # 각 target 항목을 num 번씩 복사하여 확장\n",
    "    targets_expanded = [tar for tar in targets for _ in range(num)]\n",
    "\n",
    "    # 병합\n",
    "    merged_data = [inp + \"####\" + tar for inp, tar in zip(inputs, targets_expanded)]\n",
    "    # 파일로 저장\n",
    "    with open(file_name, 'w', encoding='UTF-8') as file:\n",
    "        for line in merged_data:\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "    # 정보 출력\n",
    "    print('Input count:', len(inputs))\n",
    "    print('Expanded target count:', len(targets_expanded))\n",
    "    print('Merged data count:', len(merged_data))\n",
    "    print('Data saved. Total count:', len(merged_data))\n",
    "\n",
    "def dev_sampleing(file_path, file_name, formatted):\n",
    "    seed = 2024  # seed 값\n",
    "    train_ratio = 0.9  # train 비율 (90%)\n",
    "    source_file = os.path.join(file_path,file_name)\n",
    "    lines = []\n",
    "    with open(source_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if formatted == True:\n",
    "                formatted_line = format_line(line.strip())\n",
    "            else:\n",
    "                formatted_line = line.strip()\n",
    "            lines.append(formatted_line)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    random.seed(seed)\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    # Split the data\n",
    "    split_index = int(len(lines) * train_ratio)\n",
    "    train_data = lines[:split_index]\n",
    "    dev_data = lines[split_index:]\n",
    "\n",
    "    train_file = os.path.join(file_path,f'train.txt')\n",
    "    dev_file = os.path.join(file_path,f'dev.txt')\n",
    "    \n",
    "    # Save the data to the output files\n",
    "    with open(train_file, 'w') as file:\n",
    "        file.writelines(line + '\\n' for line in train_data)\n",
    "    \n",
    "    with open(dev_file, 'w') as file:\n",
    "        file.writelines(line + '\\n' for line in dev_data)\n",
    "    \n",
    "    print(f\"Train data count: {len(train_data)}, Dev data count: {len(dev_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ecb088c-7e3b-4458-a5aa-a533c26449a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  1264\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_1.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_1_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_2.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_2_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_3.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_3_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_4.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_4_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_5.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_5_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_6.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_6_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_7.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_7_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_8.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_8_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_9.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_9_train.txt.\n",
      "Data read. Total count:  1264\n",
      "Input count: 1264\n",
      "Expanded target count: 1264\n",
      "Merged data count: 1264\n",
      "Data saved. Total count: 1264\n",
      "File zero_asqp_rest16_10.txt was copied to /home/elicer/ABSA/data/asqp/rest15 with the new name zero_asqp_rest16_10_train.txt.\n"
     ]
    }
   ],
   "source": [
    "task = 'asqp'\n",
    "data = 'rest16'\n",
    "data_to = 'rest15'\n",
    "\n",
    "source_folder = f'/home/elicer/LLMSS/outputs/{task}/{data}'\n",
    "destination_folder = f'/home/elicer/ABSA/data/{task}/{data_to}'\n",
    "target_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "\n",
    "file_name = os.path.join(target_folder, 'train_org.txt')\n",
    "_, targets = split_read(file_name)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    file_name = f'zero_{task}_{data}_{i}.txt'\n",
    "    new_file_name = f'zero_{task}_{data}_{i}_train.txt'\n",
    "    \n",
    "    source_path = os.path.join(source_folder, file_name)\n",
    "    destination_path = os.path.join(destination_folder, new_file_name)\n",
    "\n",
    "    _, inputs = split_read(source_path)\n",
    "    merge_save(inputs, targets, destination_path, 1)\n",
    "    \n",
    "    print(f'File {file_name} was copied to {destination_folder} with the new name {new_file_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e3749f-8d15-44a3-ab78-f71dbe166bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_read(file_name):\n",
    "    inputs, strips =[], []\n",
    "    with open(file_name, 'r', encoding='UTF-8') as fp:\n",
    "        for line in fp:\n",
    "            input, strip = [], []\n",
    "            if line != '':\n",
    "                input = line.strip()\n",
    "                strip = line.replace(\" \", \"\").lower()\n",
    "                inputs.append(input)\n",
    "                strips.append(strip)\n",
    "    print('Data read. Total count: ',len(strips))\n",
    "    return inputs, strips\n",
    "\n",
    "def matching_indexes(strips1, strips2):\n",
    "    matching_indexes = []\n",
    "    for index, item in enumerate(strips1):\n",
    "        if item in strips2:\n",
    "            matching_indexes.append(index)\n",
    "    print('Total matching data count: ',len(matching_indexes))\n",
    "    return matching_indexes\n",
    "\n",
    "def remove_data(lst, indexes):\n",
    "    list = lst\n",
    "    return [item for index, item in enumerate(list) if index not in indexes]\n",
    "\n",
    "def extract_data(lst, indexes):\n",
    "    list = lst\n",
    "    return [list[index] for index in indexes if index < len(list)]\n",
    "\n",
    "def save(file_name, inputs):\n",
    "    with open(file_name, 'w', encoding='UTF-8') as file:\n",
    "        for line in inputs:\n",
    "            file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7ce675-0426-409b-9c69-aa431ea0aa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  834\n",
      "Data read. Total count:  1264\n",
      "Total matching data count:  658\n"
     ]
    }
   ],
   "source": [
    "# train data check\n",
    "task = 'asqp'\n",
    "data = 'rest15'\n",
    "source_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "source_path = os.path.join(source_folder, 'train.txt')\n",
    "inputs, strips1 = strip_read(source_path)\n",
    "\n",
    "data = 'rest16'\n",
    "source_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "source_path = os.path.join(source_folder, 'train_org.txt')\n",
    "inputs1, strips2 = strip_read(source_path)\n",
    "\n",
    "indexes1 = matching_indexes(strips2, strips1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1da843-c7a9-4310-9d0d-012d16130038",
   "metadata": {},
   "outputs": [],
   "source": [
    "asqp_16 = remove_data(inputs1, indexes1)\n",
    "print('ASQP rest16 train data : ',len(inputs_16))\n",
    "\n",
    "task = 'asqp'\n",
    "data = 'rest15'\n",
    "source_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "\n",
    "for i in range(1,11):\n",
    "    file_name = f'zero_asqp_rest16_{i}_train.txt'\n",
    "    source_path = os.path.join(source_folder, file_name)\n",
    "    input, strips2 = strip_read(source_path)\n",
    "    row_data = remove_data(input, indexes1)\n",
    "    print('asqp rest16 train data : ',len(row_data))\n",
    "    source_path = os.path.join(source_folder, f'{file_name}')\n",
    "    save(source_path, row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e14ed4a-871a-408a-bd9d-01272863c550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n",
      "Data read. Total count:  1264\n",
      "asqp rest16 train data :  658\n"
     ]
    }
   ],
   "source": [
    "#task = 'acos'\n",
    "#data = 'rest16'\n",
    "#source_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "#source_path = os.path.join(source_folder, 'train.txt')\n",
    "#inputs2, strips3 = strip_read(source_path)\n",
    "# indexes2 = matching_indexes(strips3, strips1)\n",
    "# strips4 = remove_data(strips3, indexes2)\n",
    "# indexes3 = matching_indexes(strips4, strips2)\n",
    "# indexes4 = sorted(indexes2 + indexes3)\n",
    "\n",
    "# acos_16 = remove_data(inputs2, indexes4)\n",
    "# print('ACOS rest16 train data : ',len(acos_16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7c76004d-884f-47dc-8e8e-78ec4945656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_1.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_1_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_2.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_2_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_3.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_3_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_4.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_4_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_5.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_5_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_6.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_6_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_7.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_7_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_8.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_8_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_9.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_9_dev.txt.\n",
      "Data read. Total count:  316\n",
      "File /home/elicer/LLMSS/outputs/asqp/rest16/zero_asqp_dev_10.txt copied to the new name /home/elicer/ATOSS/data/asqp/dev/zero_asqp_rest16_10_dev.txt.\n"
     ]
    }
   ],
   "source": [
    "task = 'asqp'\n",
    "data = 'rest16'\n",
    "# LLMSS/ouputs/asqp/rest15/zero_asqp_rest15_1.txt\n",
    "# LLMSS/outputs/asqp/rest15/zero_asqp_rest15_1.txt'\n",
    "source_folder = f'/home/elicer/LLMSS/outputs/{task}/{data}'\n",
    "target_folder = f'/home/elicer/ATOSS/data/{task}/dev'\n",
    "\n",
    "for i in range(1, 11):\n",
    "    file_name = f'zero_{task}_dev_{i}.txt'\n",
    "    new_file_name = f'zero_{task}_{data}_{i}_dev.txt'\n",
    "    \n",
    "    source_path = os.path.join(source_folder, file_name)\n",
    "    target_path = os.path.join(target_folder, new_file_name)\n",
    "    \n",
    "    inputs, output = strip_read(source_path)\n",
    "    if data == 'rest16':\n",
    "        inputs = remove_data(inputs, indexes1)\n",
    "    \n",
    "    save(target_path, inputs)\n",
    "    \n",
    "    print(f'File {source_path} copied to the new name {target_path}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7f1c7a5-0442-4b96-bfcd-242a860db2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658\n"
     ]
    }
   ],
   "source": [
    "print(len(indexes1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eef8870a-d1fb-40c2-8d3f-a39e30a52e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for i in range(1, 11):\n",
    "    file_name = f'zero_{task}_{data}_{i}_train.txt'\n",
    "    file_list.append(file_name)\n",
    "\n",
    "lines_seen = set()  # 중복된 라인을 추적하기 위한 집합\n",
    "unique_lines = []  # 중복되지 않은 라인을 저장할 리스트\n",
    "\n",
    "# 입력 파일들을 순회하면서 각 파일 처리\n",
    "for file_name in file_list:\n",
    "    merge_path = os.path.join(target_folder, file_name)\n",
    "    with open(merge_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line not in lines_seen:  # 중복 검사\n",
    "                lines_seen.add(line)\n",
    "                unique_lines.append(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d679dce2-e1c4-4220-ac8e-5a2ff7eb1fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "834 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_1_train.txt\n",
      "1668 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_10_train.txt\n",
      "2502 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_2_train.txt\n",
      "3336 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_3_train.txt\n",
      "4170 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_4_train.txt\n",
      "5004 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_5_train.txt\n",
      "5838 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_6_train.txt\n",
      "6672 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_7_train.txt\n",
      "7506 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_8_train.txt\n",
      "8340 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest15_9_train.txt\n",
      "8946 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_1_train.txt\n",
      "9552 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_10_train.txt\n",
      "10158 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_2_train.txt\n",
      "10764 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_3_train.txt\n",
      "11370 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_4_train.txt\n",
      "11976 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_5_train.txt\n",
      "12582 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_6_train.txt\n",
      "13188 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_7_train.txt\n",
      "13794 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_8_train.txt\n",
      "14400 lines loaded from /home/elicer/ATOSS/data/asqp/train/zero_asqp_rest16_9_train.txt\n",
      "14400 lines saved to /home/elicer/ATOSS/data/asqp/train2.txt\n"
     ]
    }
   ],
   "source": [
    "def merge_folder(folder_path, output_file_path):\n",
    "    merge_lines = []\n",
    "    files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, 'r', encoding='UTF-8') as fp:\n",
    "            for line in fp:\n",
    "                # 파일의 각 라인을 바로 merge_lines에 추가\n",
    "                merge_lines.append(line.rstrip('\\n'))\n",
    "        print(f\"{len(merge_lines)} lines loaded from {file_path}\")\n",
    "\n",
    "    # 모든 파일을 읽은 후에 한 번에 결과 파일에 쓰기\n",
    "    with open(output_file_path, 'w', encoding='UTF-8') as file:\n",
    "        for line in merge_lines:\n",
    "            file.write(line + '\\n')  # 여기서 line은 문자열이므로 직접 파일에 쓸 수 있음\n",
    "    print(f\"{len(merge_lines)} lines saved to {output_file_path}\")                \n",
    "            \n",
    "# 사용 예시\n",
    "folder_path = '/home/elicer/ATOSS/data/asqp/train'  # 폴더 경로를 지정하세요.\n",
    "output_file_path = '/home/elicer/ATOSS/data/asqp/train2.txt'  # 결과 파일의 이름과 경로\n",
    "\n",
    "# 함수 호출\n",
    "merge_folder(folder_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c52c7c-3dc0-4688-ae46-4457008a7426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa59b2-cf5d-4b1f-81e6-fcea7d59c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3e6a5987-5ba5-4315-966f-81ab5c68d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'asqp'\n",
    "data = 'rest16'\n",
    "source_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "source_path = os.path.join(source_folder, 'train_asqp_rest16_only.txt')\n",
    "save(source_path, asqp_16)\n",
    "source_path = os.path.join(source_folder, 'train_acos_rest16_only.txt')\n",
    "save(source_path, acos_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6cd5e-d67d-45ed-b9b5-be80887c91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model moving\n",
    "\n",
    "task = 'asqp'\n",
    "data = 'rest15'\n",
    "mothod = 'dlo'\n",
    "\n",
    "if mothod == 'mvp':\n",
    "    method_path = 'top_5_post_data1.0'\n",
    "elif mothod == 'dlo':\n",
    "    method_path = 'top_1_post_data1.0'\n",
    "# model load\n",
    "model_path = f'/home/elicer/#backup/mvp_seo/outputs/{task}/{data}/{method_path}/final'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "\n",
    "model_path = f'/home/elicer/ABSA/outputs/{mothod}/{task}/{data}/{method_path}/final'\n",
    "# save load\n",
    "model.model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp_seo",
   "language": "python",
   "name": "mvp_seo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
