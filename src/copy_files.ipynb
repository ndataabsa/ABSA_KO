{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c001de3-5966-450c-86f9-69e20ffd2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "def format_line(line):\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'\\s*,\\s*', ' , ', line)\n",
    "    line = re.sub(r'\\s*\\.\\s*', ' . ', line)\n",
    "    line = re.sub(r\"n \\s*'\\s*t\", \"n't\", line)\n",
    "    return line\n",
    "\n",
    "def split_read(file_name):\n",
    "    inputs, targets =[], []\n",
    "    with open(file_name, 'r', encoding='UTF-8') as fp:\n",
    "        for line in fp:\n",
    "            input, target = [], []\n",
    "            input, target = line.strip().split('####')\n",
    "            if line != '':\n",
    "                inputs.append(input)\n",
    "                targets.append(target)\n",
    "    print('Data read. Total count: ',len(targets))\n",
    "    return inputs, targets\n",
    "\n",
    "def merge_save(inputs, targets, file_name, num=1):\n",
    "    # 각 target 항목을 num 번씩 복사하여 확장\n",
    "    targets_expanded = [tar for tar in targets for _ in range(num)]\n",
    "\n",
    "    # 병합\n",
    "    merged_data = [inp + \"####\" + tar for inp, tar in zip(inputs, targets_expanded)]\n",
    "    # 파일로 저장\n",
    "    with open(file_name, 'w', encoding='UTF-8') as file:\n",
    "        for line in merged_data:\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "    # 정보 출력\n",
    "    print('Input count:', len(inputs))\n",
    "    print('Expanded target count:', len(targets_expanded))\n",
    "    print('Merged data count:', len(merged_data))\n",
    "    print('Data saved. Total count:', len(merged_data))\n",
    "\n",
    "def dev_sampleing(file_path, file_name, formatted):\n",
    "    seed = 2024  # seed 값\n",
    "    train_ratio = 0.9  # train 비율 (90%)\n",
    "    source_file = os.path.join(file_path,file_name)\n",
    "    lines = []\n",
    "    with open(source_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if formatted == True:\n",
    "                formatted_line = format_line(line.strip())\n",
    "            else:\n",
    "                formatted_line = line.strip()\n",
    "            lines.append(formatted_line)\n",
    "    \n",
    "    # Shuffle the data\n",
    "    random.seed(seed)\n",
    "    random.shuffle(lines)\n",
    "    \n",
    "    # Split the data\n",
    "    split_index = int(len(lines) * train_ratio)\n",
    "    train_data = lines[:split_index]\n",
    "    dev_data = lines[split_index:]\n",
    "\n",
    "    train_file = os.path.join(file_path,f'train.txt')\n",
    "    dev_file = os.path.join(file_path,f'dev.txt')\n",
    "    \n",
    "    # Save the data to the output files\n",
    "    with open(train_file, 'w') as file:\n",
    "        file.writelines(line + '\\n' for line in train_data)\n",
    "    \n",
    "    with open(dev_file, 'w') as file:\n",
    "        file.writelines(line + '\\n' for line in dev_data)\n",
    "    \n",
    "    print(f\"Train data count: {len(train_data)}, Dev data count: {len(dev_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2872168b-f2eb-44ee-8a41-43daee37f95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  834\n"
     ]
    }
   ],
   "source": [
    "task = 'asqp'\n",
    "data = 'rest15'\n",
    "data_to = 'rest16'\n",
    "# LLMSS/ouputs/asqp/rest15/zero_asqp_rest15_1.txt\n",
    "# LLMSS/outputs/asqp/rest15/zero_asqp_rest15_1.txt'\n",
    "source_folder = f'/home/elicer/LLMSS/outputs/{task}/{data}'\n",
    "destination_folder = f'/home/elicer/ABSA/data/{task}/{data_to}'\n",
    "target_folder = f'/home/elicer/ABSA/data/{task}/{data}'\n",
    "\n",
    "file_name = os.path.join(target_folder, 'train.txt')\n",
    "_, targets = split_read(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8cd6fd9-327d-443f-a42d-8220506dbfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_1.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_1_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_2.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_2_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_3.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_3_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_4.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_4_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_5.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_5_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_6.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_6_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_7.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_7_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_8.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_8_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_9.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_9_train.txt.\n",
      "Data read. Total count:  834\n",
      "Input count: 834\n",
      "Expanded target count: 834\n",
      "Merged data count: 834\n",
      "Data saved. Total count: 834\n",
      "File zero_asqp_rest15_10.txt was copied to /home/elicer/ABSA/data/asqp/rest16 with the new name zero_asqp_rest15_10_train.txt.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    # 복사할 파일 이름과 새 파일 이름 설정\n",
    "    file_name = f'zero_{task}_{data}_{i}.txt'\n",
    "    new_file_name = f'zero_{task}_{data}_{i}_train.txt'\n",
    "    \n",
    "    # 원본 파일과 대상 파일의 전체 경로 생성\n",
    "    source_path = os.path.join(source_folder, file_name)\n",
    "    destination_path = os.path.join(destination_folder, new_file_name)\n",
    "\n",
    "    _, inputs = split_read(source_path)\n",
    "    merge_save(inputs, targets, destination_path, 1)\n",
    "    \n",
    "    print(f'File {file_name} was copied to {destination_folder} with the new name {new_file_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddda5a-0322-40e4-bf35-0a9518f2971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3749f-8d15-44a3-ab78-f71dbe166bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e86555-5c48-4738-9b0b-f2522bbf943c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6cd5e-d67d-45ed-b9b5-be80887c91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'asqp'\n",
    "data = 'rest15'\n",
    "mothod = 'dlo'\n",
    "\n",
    "if mothod == 'mvp':\n",
    "    method_path = 'top_5_post_data1.0'\n",
    "elif mothod == 'dlo':\n",
    "    method_path = 'top_1_post_data1.0'\n",
    "# model load\n",
    "model_path = f'/home/elicer/#backup/mvp_seo/outputs/{task}/{data}/{method_path}/final'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "tfm_model = MyT5ForConditionalGeneration.from_pretrained(model_path)\n",
    "model = T5FineTuner(args, tfm_model, tokenizer)\n",
    "\n",
    "model_path = f'/home/elicer/ABSA/outputs/{mothod}/{task}/{data}/{method_path}/final'\n",
    "# save load\n",
    "model.model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvp",
   "language": "python",
   "name": "mvp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
